{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-16 12:42:09--  http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
      "Распознаётся ufldl.stanford.edu (ufldl.stanford.edu)… 171.64.68.10\n",
      "Подключение к ufldl.stanford.edu (ufldl.stanford.edu)|171.64.68.10|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 182040794 (174M) [text/plain]\n",
      "Сохранение в: «train_32x32.mat»\n",
      "\n",
      "train_32x32.mat     100%[===================>] 173,61M  8,87MB/s    за 25s     \n",
      "\n",
      "2022-03-16 12:42:35 (6,95 MB/s) - «train_32x32.mat» сохранён [182040794/182040794]\n",
      "\n",
      "--2022-03-16 12:42:35--  http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
      "Повторное использование соединения с ufldl.stanford.edu:80.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 64275384 (61M) [text/plain]\n",
      "Сохранение в: «test_32x32.mat»\n",
      "\n",
      "test_32x32.mat      100%[===================>]  61,30M  8,47MB/s    за 7,1s    \n",
      "\n",
      "2022-03-16 12:42:42 (8,60 MB/s) - «test_32x32.mat» сохранён [64275384/64275384]\n",
      "\n",
      "ЗАВЕРШЕНО --2022-03-16 12:42:42--\n",
      "Общее время: 33s\n",
      "Загружено: 2 файлов, 235M за 32s (7,32 MB/s)\n"
     ]
    }
   ],
   "source": [
    "!bash download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/5dmjvwj50ysf44p31147cjt40000gn/T/ipykernel_34072/2810386256.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
      "/var/folders/qx/5dmjvwj50ysf44p31147cjt40000gn/T/ipykernel_34072/2810386256.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n"
     ]
    }
   ],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for L1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for L1_B\n",
      "Gradient check passed!\n",
      "Checking gradient for L2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for L2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for L1_W\n",
      "Gradient check passed!\n",
      "Checking gradient for L1_B\n",
      "Gradient check passed!\n",
      "Checking gradient for L2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for L2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 27.828631, Train accuracy: 0.214889, val accuracy: 0.215000\n",
      "Loss: 23.503394, Train accuracy: 0.249778, val accuracy: 0.253000\n",
      "Loss: 19.884021, Train accuracy: 0.299889, val accuracy: 0.300000\n",
      "Loss: 16.931150, Train accuracy: 0.344556, val accuracy: 0.339000\n",
      "Loss: 14.385688, Train accuracy: 0.387333, val accuracy: 0.396000\n",
      "Loss: 12.123939, Train accuracy: 0.424222, val accuracy: 0.426000\n",
      "Loss: 10.716846, Train accuracy: 0.461444, val accuracy: 0.470000\n",
      "Loss: 9.128000, Train accuracy: 0.485889, val accuracy: 0.486000\n",
      "Loss: 7.969772, Train accuracy: 0.502556, val accuracy: 0.488000\n",
      "Loss: 6.684177, Train accuracy: 0.531000, val accuracy: 0.516000\n",
      "Loss: 6.131888, Train accuracy: 0.557222, val accuracy: 0.538000\n",
      "Loss: 5.408971, Train accuracy: 0.566889, val accuracy: 0.548000\n",
      "Loss: 4.803028, Train accuracy: 0.577000, val accuracy: 0.555000\n",
      "Loss: 4.300332, Train accuracy: 0.583667, val accuracy: 0.562000\n",
      "Loss: 3.925002, Train accuracy: 0.594889, val accuracy: 0.582000\n",
      "Loss: 3.411706, Train accuracy: 0.606333, val accuracy: 0.581000\n",
      "Loss: 3.261721, Train accuracy: 0.612000, val accuracy: 0.594000\n",
      "Loss: 3.310731, Train accuracy: 0.616556, val accuracy: 0.595000\n",
      "Loss: 3.076307, Train accuracy: 0.618333, val accuracy: 0.598000\n",
      "Loss: 2.825875, Train accuracy: 0.633111, val accuracy: 0.615000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f844aa15730>]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f843b21da30>]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAApHUlEQVR4nO3dd3hUVf7H8fdJQgIkoSaBEDqEXgQioNgRpajYBRRYsaGLP9fVVdd1dde2q666dtaCiiLYsCGIFUEUFZDeQSIpQGgJpM/M+f1xB4kxIQMkuZPJ5/U880y5Z2a+uUw+nJw591xjrUVERGq+MLcLEBGRyqFAFxEJEQp0EZEQoUAXEQkRCnQRkRAR4dYbx8XF2bZt27r19iIiNdKSJUt2WWvjy9rmWqC3bduWxYsXu/X2IiI1kjEmtbxtGnIREQkRCnQRkRChQBcRCREKdBGREKFAFxEJEQp0EZEQoUAXEQkRCnQRkWqSnVfM8/M38/2W3VXy+q4dWCQiUltszjrAKwu38s6SNPKLvVx/WgcGtG9a6e+jQBcRqQLWWhZs3MWUhT8zb30WkeFhnHdcC64c1JbuLRpWyXsq0EVEKlF+kZeZP6Xx8sKtbNp5gLiYKG4+sxNjBrQmPjaqSt9bgS4iUgky9uUz9btUpv/wC9n5xfRIasBjl/ZmRK9EoiLCq6UGBbqIyFGy1rL0l31MWfgzn6zajrWWs7s3Z8JJ7Uhp0xhjTLXWo0AXETlCRR4fc1ZlMmXhVpZv20ds3QiuOqkd405oQ8vG9V2rS4EuIoLT2y4o9rG/sJjcQi+5hR72F3jILfRwwH/JLfSwO7eID5alsyOnkPbx0dw3sjsX9m1JdJT7cep+BSIiVcTrs2Rm5/PL7jx+2XPokp1f7IR0qcD22YpfM8zAoI5x/PuiXpyaHE9Y2BEOq3iKwPqgTt2j+6EOQ4EuIjVabqHnUFj7gzt1Tx7b9uSRtjePYu+hlI4IMyQ1rkfj+pHE1o2gWWxdYupGEBPlXKKjIvz3w4mJqkN0VPiv22L82+rVCT+6sXFPESx/A+Y/CilXwsl/rsS94P/5Kv0VRUQqWZHHx9bduWzYsZ+NOw6Qujv319DedaDoN20b1I2gTdNouiU24OzuzWnTtD6tmziXxIZ1iQiv5gPkvcWw7A1Y8B/Y9wskpUBS3yp5KwW6iASN0sG9ced+Nuw4wNZduXj84yHGQIuG9WjTtD5ndm1Gqyb1fw3tNk2iaVi/jss/hd/vgrwfjHgcOg52fogqoEAXkWpX7PWxdVcuG3YcYMOO/Wza6Vz/XCq42zSpT3KzWM7u3ozkhFiSm8XQIT6GunWqZ173UfEWw/LpMP8RJ8hb9IURj0HHM6ssyA9SoItItdiSdYCPV2TyyertbNix/9ex7YPB3TEhliHdmtGpWQ0J7tK8xbB8hj/IU50gH/4oJA+p8iA/KKBAN8YMBZ4AwoEXrbX/LqPNacB/gTrALmvtqZVWpYjUSKm7c5m1IpNZKzJZm5mDMZDSpjFXn9yeTs1iSE6IpWNCDQvu0rzFsOJNJ8j3boUWfWD4I5B8VrUF+UEVBroxJhx4BhgCpAE/GmM+tNauKdGmEfAsMNRa+4sxJqGK6hWRILdtTx4fr8zk4xWZrEzPBqBfm8bcfU43hvdMpHnDyp+u5wqvp0SQ/wyJx8HoN6HT2dUe5AcF0kPvD2yy1m4BMMbMAEYCa0q0GQPMtNb+AmCt3VnZhYpI8Erfl8/sFZnMWpnJ8m37AOjdqhF3jejKsJ6JJDWq526BlcnrgZVvwdcPB02QHxRIoCcB20rcTwMGlGrTCahjjJkHxAJPWGunln4hY8y1wLUArVu3Ppp6RSRIbM8u8PfEM1j6yz4AeiY15I5hXRjRM5FWTdw7BP6oeD2QtwsO7ITcrEOXkvcP7IScdMjbDYm9YfQM6DTU9SA/KJBAL6vS0sdTRQD9gMFAPeA7Y8wia+2G3zzJ2ueB5wFSUlICOCZLRILJjpwCPlm1nVkrMvhx614AuiU24C9nd2ZEz0TaxkVXfRE+LxTng7cIPAXgKfRfCko85r/2ltjmKdE+f8/vgzp/T9nvFx4FMQkQHQexiZDYCzoPdy5BEuQHBRLoaUCrEvdbAhlltNllrc0Fco0x84HewAZEpEbbnl3AnFWZzF6ZyeLUvVgLnZvFcsuQTgzvlUiH+JiqL8JaSPsRlk6F1e9B0YFje73IWIiJh+gEaNoR2pzo3I6O84d3wqEQj2oQdMFdnkAC/Ucg2RjTDkgHRuGMmZf0AfC0MSYCiMQZknm8MgsVkeqTmZ3P7JXbmb0ykyWpTk+8S/NY/jS4EyN6NadjQmz1FLJ/B6yYAT+9Drs2QJ1o6DYSErpARF0Ij3SuI/zX4VEQUeLym/t1Dz0WHpoztiv8qay1HmPMJGAuzrTFKdba1caYif7tk621a40xnwArAB/O1MZVVVm4iFSu9H35zFnp9MQPjol3aV7NPXFwpgFu/MwJ8Q2fgPVCqwFw3tPQ/XyIqqb/TGogY607Q9kpKSl28eLFrry3iDjS9uYxZ+V2Pl6ZyTL/7JRuiQ0Y0SuRYT2a0766QhwgawP89JpzcE7uTmfY47jRcNwVEN+p+uoIcsaYJdbalLK2hebfHSJSJmstqbvzmLvaGU5ZnubME++R1IDbhnZmeI9q+mLzoML9zpj40tcg7QcIi3BmjfS5wjlUPjxI1mWpIRToIiHKWssve/JYmZ7NqvQcVmdksyo9m715xQD0aulMMRzWozltmgYY4j4f/DwPCnJ+O3b963h1yfHsEttKfqloLfzynTOksvo9KM6DuE4w5D7oPcr5MlKOigJdJAT4fJYtu3J/De2V6dmszshhf4EHgDrhhs7NYzm7e3N6JDXk1E7xRz5PPGMZzP6L05M+UuElQh7rzOOOjIWel0CfsdAypcbMJAlmCnSRGsbj9bE5K7dEcGezJiOH3CIvAJERYXRNbMDI41rQo0VDeiQ1pFOzWCIjjnId8Nzd8OW9sORVZxrfeU85a3ofnNP961zvkvPBy3rs4NzwYmeaYLeREFmNwzu1gAJdpAbI2l/IV+t38uXanSzYmPVreNerE063Fg24JKUV3Vs0oEdSQzomxFCnMk7i4PPC4inw5f3OWPfA6+HU26Feo2N/bakSCnSRIGStZU1mDl+u3ckX63ayPG0f1kJiw7qM7JPE8W0b0zOpIe3iYgg/0nNaBiL1W5h9G+xYCe1OgWEPQ0LXyn8fqVQKdJEgUVDs5dvNu/hi7U6+XLeTzOwCjIHeLRvx5zM7MbhrM7omxh7d+SwDlZMBn90NK9+GBi3hkledoRGNb9cICnQRF+3IKfAH+A6+2bSLgmIf0ZHhnJwcz81DEji9cwLxsVFVX4inEBY9C18/Aj4PnHIbnHQzRNawBbZqOQW6SDXy+SyrMrL5Yu1Ovli3g1XpOQC0bFyPUce35owuCQxo34SoiGo84cPGz2HObbBns7Pg1NkPQpN21ff+UmkU6CJVbG9uEfM3ZvH1+izmb8xi14Eiwgz0bd2Y24d2YXDXBJITYqp2KKUse36GuXfC+tnOAlWXvwvJZ1ZvDVKpFOgilczns6xMz2be+izmbdjJ8m378FloXL8Op3SK57TO8ZzaKYEm0ZHuFFiUB988BgufdI7EPPOfMPAG54AgqdEU6CKVYE9uEQs2ZjFvfRbzN2SxO7cIY6BXy0bceEYyp3WOp1fLRlUzI6UiBdmQ8ROkL4WMpfDLImcN8J6XwpB7oUFi9dckVUKBLnIUfD7LivRs5q3fybz1Wb9OK2wSHckpyXGc1jmBk5PjaBpTDV9ollSUB9tXOsF9MMB3bzq0vXFbZxri8Vc7B/dISFGgixyBXQcKeWjOOr5Yt5M9/l5475aNuGlwMqd1TqBnUsPq64V7i2HH6hLh/RPsXOssNwvO2XVa9HXWR2nR1zkbff0m1VObuEKBLhKgJal7uGHaUvblFTO8ZyKndY7n5OT46hkL93lh10YntA8G+PaVziH2APUaO6HdaSgk9XVuayil1lGgi1TAWssr327lgY/XktS4Hu/d0J9uLRpU5RvCvtRDQybpP0HmskOnXasTDS2Og/7XHArvxm118I8o0EUOJ7fQw+3vrmDWikyGdGvGfy7pTcN6lbxG9/7tJcLbP3Ry8ITF4ZHQvCf0Hu0MmST1dZaaDavGeepSYyjQRcqxaed+Jr6+lC1ZB7hjWBeuO6X9sc8VLy6AbYucEx6n/+SE937/OddNGCR0gy7DnV53Ul9I6K7phBIwBbpIGT5ansHt766gfmQ4r189gBM7xB39i+VkwsZPYcNc2DIPinOdx5t0gLaDDoV381461F6OiQJdpIQij49/zVnLywu30q9NY54Z05fmDese2Yv4fE7Pe+Nc5yTHmcudxxu2cmacdDrbOemxlqGVSqZAF/Hbnl3AH99YypLUvUwY1I6/Du8S+LriBTmw5SunF77xU+fAHRMGLfvD4HucEE/opi8upUop0EWAbzft4sbpP1FQ7OXpMX04p1eLip+0e7MT4Bs+cdYP9xVD3YbQcYgT4B3P1LxvqVYKdKnVfD7L5Pmb+c/c9bSPj2HyFX3pmBBb/hPy9sDC/8K6jw8dgRnfBU64wZkD3rI/hOvXStyhT57UWtn5xdzy1nI+X7uDc3ol8tBFvYiOOsyvxOr3YfatTqh3OB36XwedznLmgIsEAQW61EqrM7K5/vWlZOzL5x/ndmP8iW3Ln5K4fzt8fAusmwWJx8HY95y54SJBRoEutc7bi7dx1/uraFw/kjevG0i/NuWMc1sLy6Y5a4Z7Cp2VCQf+UUMqErT0yZRaw+uz3P/xGl5euJUTOzTlydF9iCtvNcS9W+Gjm5x5420GwblPQlzH6ixX5Igp0KVW2F9QzI3Tf2Le+iwmDGrHncO7EFHWlESfF354Hr64F0w4jHgM+l0JYQFOXxRxkQJdQt62PXlc9eqPbMnK5YELenD5gDZlN9y5Dj68EdJ+gOSz4JzHoWHL6i1W5Bgo0CWk/bh1D9e9tgSP18fUCf05sWMZh/B7imDhEzD/YYiMgQtfgJ6X6CAgqXEU6BKy3l2Sxl9nriSpcT1eGp9C+/iY3zdKX+r0ynesgh4XwdCHICa++osVqQQKdAk5Pp/lkU/X89y8zZzYoSnPXt6XRvVLrVhYnA9fPQjfPQ0xzWDUdGeVQ5EaTIEuISWvyMPNby5j7uodjO7fmntHdv/9eixbv3F65Xu2QN/xcNZ9ziH7IjWcAl1CRmZ2Ple9sph123P4+zndmDCo1MFC1sKCR+HL+5yjO8d9CO1Pda1ekcqmQJeQsHzbPq6eupj8Ii8vjT+e07sk/LZBcT58MAlWveN84XnuExAZ7U6xIlVEgS413qwVGdzy1nLiY6OYdvUAOjUrtbhWTgbMGAMZy5ylbE+6WTNYJCQp0KXGstby5BebePzzDaS0acz/xvajaekjP9OWOGFedABGvaEvPiWkKdClRioo9nLbOyv4cHkGF/ZN4l8X9iQqotSJk1e8DR/8EWKbwdhPoVl3d4oVqSYBHc9sjBlqjFlvjNlkjLmjjO2nGWOyjTHL/Je7K79UEcfO/QWMen4RHy7P4LahnXn0kt6/DXOfDz7/J8y8GlqmwDVfKcylVqiwh26MCQeeAYYAacCPxpgPrbVrSjVdYK09pwpqFAHA4/Xx4fIMHpm7nn15xUy+oh9DezT/baPC/TDzOlj/sTMlcfh/ICKy7BcUCTGBDLn0BzZZa7cAGGNmACOB0oEuUiWKvT7e+ymdZ77aROruPLo0j+WFcSn0SCo1d3zvVpg+GrLWwbCHof+1+vJTapVAAj0J2FbifhowoIx2JxhjlgMZwK3W2tWlGxhjrgWuBWjduvWRVyu1SpHHx7tL03jmq02k7c2ne4sG/G9sP4Z0bUZYWKmg3roQ3hoLPg9c8S50OMOdokVcFEigl9XFsaXuLwXaWGsPGGOGA+8Dyb97krXPA88DpKSklH4NEQAKPV7eWpzGc19tIiO7gN4tG/LP87pzRpeEss8qtOQV54xCjdvC6De1brnUWoEEehrQqsT9lji98F9Za3NK3J5tjHnWGBNnrd1VOWVKbVBQ7GXGD78w+estbM8poG/rRvzrol6ckhxXdpB7PfDp3+D7ydBhMFw8Beo1qva6RYJFIIH+I5BsjGkHpAOjgDElGxhjmgM7rLXWGNMfZ/bM7souVkJTfpGXad+n8r/5W8jaX0j/tk149NLenNihafnn+czfC29fCVu+goE3wJD7dGo4qfUq/A2w1nqMMZOAuUA4MMVau9oYM9G/fTJwMXC9McYD5AOjrLUaUpHDyi308NqiVF5csIVdB4o4sUNTnhrdh4Htmx7+ibs2wvRRsDcVznsa+o6tnoJFgpxxK3dTUlLs4sWLXXlvcdf+/CKmLdzAOwtX4yvI4ZTWUYzp3ZBODS0U5kBBNhTk+G/nHHrs4P39mc46LJdNgzYnuP3jiFQrY8wSa21KWdv0N6pUn+w0Nn/4b5ptfoeJ5DMRIArYAXxaurGBqAZQt8Gh65jmENcJ6sfBwOuhcTmnkhOppRToUvV2baR4/mOYlW/RxudjYd1T6NxrAM0TEiCq4W9D++B1ZKxOzCxyhBToUnUyfoIFj2HXfoSXOszwDKa4/w1cOeIUIkqfdEJEjpkCXSqXtfDzfPjmMdgyj8KIGF70juTjeudxz7jTGFDRF54ictQU6FI5fD5YP9sJ8vQleKMTeKvh1TywYyAndW/PGxf1/P15PUWkUinQ5dh4i2HlO7Dwv84aKo3bsq7fvfzhp47sKw7jngu7M+r4VuXPJxeRSqNAl6NTlAc/vQbfPgXZ26BZD4rOf4F/p3ZmysI0uiY24PXRx9ExIbbi1xKRSqFAlyPj9cC3T8B3z0LeLmg1EEY8yoYGJ/B/M5axbnsaEwa147ahnalbJ7zi1xORSqNAlyPzxT+cXnnyWXDSn7GtB/L6979w/9SFxERF8PIfyjhBs4hUCwW6BG7Nh06YH381jHiUvblF3P7aEj5ds4OTk+N49NLeJMTWdbtKkVpLgS6B2b3ZOT9nUj84+0G+3byLm99cxp7cIu4a0ZUJg9r9fo1yEalWCnSpWFEevDkWwsLxXvQyj37+M899vZl2cdG8NP743585SERcoUCXw7PWOXnEzjXYy9/mrnk5TP/hFy5LacU953WjfqQ+QiLBQr+NcnhLX4Xlb8Cpt/P4z62Z/sMmJp7agTuGdXG7MhEpRQtqSPkylsHs26DDGUyNvIwnv9zEpSktuX1oZ7crE5EyKNClbPl7nZMuR8czt8v93DNrHWd2bcaDF/TUUZ8iQUpDLvJ7Ph+8NxFyMlk2ZAaT3k8lpU1jnh7TR6skigQx/XbK733zGGz4hPQBd3H5HA/t42J4cdzxOvJTJMiphy6/tWUefPUAB5JHct733WhUP4KpV/WnYf06blcmIhVQD10OycmAd67C07gjF2y7DGsMr13Vn2YNdPSnSE2gHro4vMXw9pXY4nyuD/8T6XnhTL/meNrHx7hdmYgESD10cXx2D2xbxBP1b2Tensb8b2w/erdq5HZVInIE1EMXWP0+LHqGLxpcwBM7e/HkqOM4OTne7apE5Aiph17b7dqI/WASqfW6M3HnBfzj3O6c27uF21WJyFFQD702K8qFN8eS7wtnVM5EJp7RhfEntnW7KhE5Suqh11bWwqybsVnruDbvek7r34c/D+nkdlUicgwU6LXV4imw4k0eL76I6K5ncv/5PXRIv0gNpyGX2ih9Kb45t7PA15sfWk3glVF9CNfJKURqPAV6bbN/O0XTx7LL25BnGt/Oi3/or0P6RUKEhlxqk6z1FD8/GM+BLO6pextPXzWYBnV1SL9IqFAPvbZI/Q7fG6PIKYT/C7+PB665ggQd0i8SUtRDrw3WfICdOpK04mgut/dz51WjaBsX7XZVIlLJ1EMPdYuew37yV9ZFdGF84Z95csJgurfQSZ1FQpECPVT5fPDZ3+G7p1lcbxDj9l3DE1ecwMD2Td2uTESqiAI9FHkKnTMOrZ7JvEYXMGH7Rfz74uM4q3tztysTkSqkQA81+XthxhWQ+g2ftLiBiVsG8ddhXbk0pZXblYlIFVOgh5LsNHj9Yti9idmd7uOGFR247tT2XHdqB7crE5FqoEAPFdtXwbSLoSiXT/o8yw0Lo7k0pSV3DO3idmUiUk0CmrZojBlqjFlvjNlkjLnjMO2ON8Z4jTEXV16JUqEt8+DlYYDhyxOnMnFhNGd1a8aDF/TU+iwitUiFgW6MCQeeAYYB3YDRxphu5bR7CJhb2UXKYax4yxlmadiS786YwbVz8xnQrglPju5DRLgOMxCpTQL5je8PbLLWbrHWFgEzgJFltLsReBfYWYn1SXmshQWPwcxroPVAlp05nQkzM+nULJYXxqdofRaRWiiQQE8CtpW4n+Z/7FfGmCTgAmDy4V7IGHOtMWaxMWZxVlbWkdYqB/m8MPtW+OKf0ONiNp71CuOnb6BZgyhendBf67OI1FKBBHpZg7C21P3/Ardba72HeyFr7fPW2hRrbUp8vM5ZeVQ8hfDWOPjxRRh0E9tOf4IrXllGVEQYr101gPjYKLcrFBGXBDLLJQ0oOYm5JZBRqk0KMMP/BVwcMNwY47HWvl8ZRUoJC5+AdbNg2MPs6v4Hxk3+jvwiL29PPJFWTeq7XZ2IuCiQQP8RSDbGtAPSgVHAmJINrLXtDt42xrwCzFKYV4G9qbDgUeh+Aft7T+APLywiMzufaVcPoHPzWLerExGXVRjo1lqPMWYSzuyVcGCKtXa1MWaif/thx82lEs29E0wYBWfcy7VTl7Aucz8vjEuhX5smblcmIkEgoAOLrLWzgdmlHiszyK21fzj2suR3Nn0O62bhO+Mebpq9k++27Oa/lx3H6V0S3K5MRIKEJirXBJ4imHM7NOnAf/YPZu7qHdx9TjfO75NU8XNFpNZQoNcEi56F3Zv4ocsdPLsgjcsHtGbCSe0qfp6I1CpayyXYZafD1w+zv+3Z/OGbBvRtHcs953Z3uyoRCULqoQe7z/6OtV6u2XEh0VERPHdFPyIj9M8mIr+nZAhmPy+AVe/yYcylLM5uwLOX96WZTuwsIuVQoAcrbzHMuY3sqBbctv0M7j63G8e31fREESmfAj1Y/fAC7FzDrftHMaJvO8YObON2RSIS5PSlaDDavwPfVw/yLceR2fx0ntK65iISAAV6ECr+9G5sUT6PmAlMHqulcEUkMBpyCTL2l0XUWTmDFz3D+cuYEbRsrAW3RCQw6qEHE5+XXW/dRLFtQtQZt3NScpzbFYlIDaIeehDZNOcp4g+sY06LSUw4XQcPiciRUaAHifT0bcT/+DA/hfdi1Pj/05egInLEFOhBoKDYy4qpt1KfAuIve5JonUJORI6CAt1l1lqefeNtzi6YS0ancbTs1MftkkSkhlKgu2zqtz9z+uZHyI9sTJsL73W7HBGpwRToLvrh5z2snfMcfcI2UW/Eg1C3gdsliUgNpmmLLtmeXcDtr89nZp038SQNIKL3KLdLEpEaToHugkKPl+unLeEqz3Qahe3HjPgPaFaLiBwjDbm44N6P1pC/bQWXm08xKVdBYi+3SxKREKAeejV7Z0ka075PZUH8dIy3MZx+p9sliUiIUKBXo/Xb93PX+yu5pflyWu1bDuc+CfW1xrmIVA4NuVSTA4Uerp+2hGaRRdxQ/Cq06At9xrpdloiEEPXQq4G1lr/OXEnarmx+aPci4Zm7YMx0CNP/pyJSeRTo1WDa97/w0fJ0Pm47k0YZ852hlqR+bpclIiFGXcQqtio9m3s/WsMjzb6g+/b34eRboN94t8sSkRCkQK9C2fnF3DBtKaPqfc8l2VOg5yVwxt/dLktEQpQCvYpYa/nL28tJyl7KP3zPQJtBMPIZHUAkIlVGY+hV5KVvfmbT2p+YHf1fwhq2gcteh4got8sSkRCmQK8CS1L38vyc7/k4+lGiIiPh8rc131xEqpwCvZLtyS3ilmnf8XLdx4hjH2bMx9CkndtliUgtoECvRD6f5ZY3l3BnwWN0C9uIueR1aKnpiSJSPfSlaCV67uvNDNryBGeF/YgZ+i/oeo7bJYlILaJAryTfbd5N1udPcnXEHGz/62Dg9W6XJCK1jIZcKsHO/QW888b/eKTOVDzJw4gY+i+3SxKRWkg99GPk9VmeePVN7vc8TmF8LyIumQJh4W6XJSK1kAL9GL086yv+lHUXvvrx1Bv/DkTWd7skEamlFOjHYOGqTZy6eBLR4T6iJ7wHMQlulyQitZjG0I9Sxq59RL4zjrZhO/CNfg/iO7tdkojUcgH10I0xQ40x640xm4wxd5SxfaQxZoUxZpkxZrEx5qTKLzV4FHu8bHzxSo5nNXvOfJyo5FPcLklEpOJAN8aEA88Aw4BuwGhjTLdSzb4AeltrjwMmAC9Wcp1B5fspt3JqwZes63YTzU4a53Y5IiJAYD30/sAma+0Wa20RMAMYWbKBtfaAtdb670YDlhC16tNXOCljCoubnEOXS/7pdjkiIr8KJNCTgG0l7qf5H/sNY8wFxph1wMc4vfTfMcZc6x+SWZyVlXU09boqJ3MTbb79K2vDO9Pzupe0FK6IBJVAAr2s1PpdD9xa+561tgtwPnBfWS9krX3eWptirU2Jj48/okJd5/Wwa+p4jLWEXfwiUVF13a5IROQ3Agn0NKBVifstgYzyGltr5wMdjDFxx1hbUNn0zj20z1/Fgs530rlrL7fLERH5nUAC/Ucg2RjTzhgTCYwCPizZwBjT0Rhn/MEY0xeIBHZXdrFuyV73Ne3WPsuXkadz5mWT3C5HRKRMFc5Dt9Z6jDGTgLlAODDFWrvaGDPRv30ycBEwzhhTDOQDl5X4krRGs3l78bxzNek2jpZXPEedcB2LJSLBKaADi6y1s4HZpR6bXOL2Q8BDlVtaELCWjNevI6F4N1/1m8LFrRPdrkhEpFzqbh5Gzncvk5Qxl+kxYzl/xHlulyMiclgK9HLYrA1EffZXvvN1Z9D4+4jQUIuIBDmlVFk8hex7bRy5vgi2nvIYHRIauF2RiEiFFOhlODD7bhrnrOXFJrdw2RkD3C5HRCQgCvRS7MbPiVk6mel2CKOumEhYmI4GFZGaQcvnlnQgi4K3r2WbLwl79gO0bqqTVYhIzaEe+kHWkv/2dYQV5jAl8W5Gn9jJ7YpERI6IAt3Pt2gy9VK/4FHGcuPokRgtvCUiNYwCHWD7Suynf+dzbx86nnMzSY3quV2RiMgRU6AX5VH05pXs9sXwUdu/cUlKq4qfIyIShGp9oPvm3knk3o3cZSbxt0tO1lCLiNRYtTvQ13xI2JKXmew5hxHnjyahgdY4F5Gaq/YGenY63g8msdLXnpWdbuS83i3crkhE5JjUznnoPi++mddQVFjIXRE389KFfTTUIiI1Xu3soX/zOGGpC/l78XgmXjCEuJgotysSETlmta+HvvUb7FcP8rH3BIp7jGJYT61xLiKhoXYF+o412Omj2WYSeSzqemaO7OF2RSIilab2DLlkp2OnXUS2pw6j8/7C3y4aSKP6kW5XJSJSaWpHoOfvw067mIID2YzOu5UrR5zC4K7N3K5KRKRShX6gFxdgZ4zBm7WBCQV/4tyzz+Lqk9u7XZWISKUL7UD3+bDvXYdJXcifCycy4IzzueG0jm5XJSJSJUI30K3Fzv0rZs373F98OUmnjOWmwcluVyUiUmVCNtDtt09hvp/MS55h2IF/5LazO+vgIREJaaEZ6Cvexnz2d2Z5B5La707uOqebwlxEQl7ozUPfMg/vexP5wduN73o9wH0jeyrMRaRWCK1Az1xB0bQxbPYm8lHXh7n/on46ybOI1BqhE+h7U8l7+QL2euryeodHufeyQQpzEalVQiPQ8/aQ/eJ5UJjHC62f4h9XDCEiPDS/HhARKU/NT73ifHa9cD51D6TzbOID3Dn+QuoozEWkFqrZyefzkvnSGJrsWcHkuDu4+arxREbU7B9JRORo1dz0s5bU124gcfuXvNroeq697mbq1gl3uyoREdfU2EDf9O4/afPzDN6rfwmX3nAf9SIV5iJSu9XIQF835zk6rnqcr6JO58wbnyE6KjS+2xURORY1LtDXLJhJx0V3sjSiD30nTSO2nk4fJyICNTDQo5t3ZGn9QbT740waxka7XY6ISNCocWMVbZJ70eb2WW6XISISdGpcD11ERMqmQBcRCREBBboxZqgxZr0xZpMx5o4ytl9ujFnhv3xrjOld+aWKiMjhVBjoxphw4BlgGNANGG2M6Vaq2c/AqdbaXsB9wPOVXaiIiBxeID30/sAma+0Wa20RMAMYWbKBtfZba+1e/91FQMvKLVNERCoSSKAnAdtK3E/zP1aeq4A5ZW0wxlxrjFlsjFmclZUVeJUiIlKhQAK9rEXFbZkNjTkdJ9BvL2u7tfZ5a22KtTYlPj4+8CpFRKRCgcxDTwNalbjfEsgo3cgY0wt4ERhmrd1dOeWJiEigjLVldrYPNTAmAtgADAbSgR+BMdba1SXatAa+BMZZa78N6I2NyQJSj7LuOGDXUT63OgR7fRD8Naq+Y6P6jk0w19fGWlvmEEeFPXRrrccYMwmYC4QDU6y1q40xE/3bJwN3A02BZ/0nZPZYa1MqeN2jHnMxxiyu6PXdFOz1QfDXqPqOjeo7NsFeX3kCOvTfWjsbmF3qscklbl8NXF25pYmIyJHQkaIiIiGipgZ6sB+4FOz1QfDXqPqOjeo7NsFeX5kq/FJURERqhpraQxcRkVIU6CIiISKoAz2AVR6NMeZJ//YVxpi+1VhbK2PMV8aYtcaY1caYm8poc5oxJtsYs8x/ubu66vO//1ZjzEr/ey8uY7ub+69zif2yzBiTY4z5U6k21b7/jDFTjDE7jTGrSjzWxBjzmTFmo/+6cTnPPezntQrre8QYs87/b/ieMaZROc897OehCuv7hzEmvcS/4/BynuvW/nuzRG1bjTHLynlule+/Y2atDcoLzpz3zUB7IBJYDnQr1WY4zroxBhgIfF+N9SUCff23Y3EOvipd32nALBf34VYg7jDbXdt/Zfxbb8c5YMLV/QecAvQFVpV47GHgDv/tO4CHyvkZDvt5rcL6zgIi/LcfKqu+QD4PVVjfP4BbA/gMuLL/Sm1/FLjbrf13rJdg7qFXuMqj//5U61gENDLGJFZHcdbaTGvtUv/t/cBaDr9oWTBybf+VMhjYbK092iOHK421dj6wp9TDI4FX/bdfBc4v46mBfF6rpD5r7afWWo//rqurnZaz/wLh2v47yDhHRV4KTK/s960uwRzogazyeKQrQVYJY0xboA/wfRmbTzDGLDfGzDHGdK/eyrDAp8aYJcaYa8vYHhT7DxhF+b9Ebu6/g5pZazPB+Y8cSCijTbDsywmUs9opFX8eqtIk/5DQlHKGrIJh/50M7LDWbixnu5v7LyDBHOiBrPIY8EqQVcUYEwO8C/zJWptTavNSnGGE3sBTwPvVWRswyFrbF+fkJH80xpxSansw7L9I4Dzg7TI2u73/jkQw7Mu/AR5gWjlNKvo8VJXngA7AcUAmzrBGaa7vP2A0h++du7X/AhbMgR7IKo8BrQRZVYwxdXDCfJq1dmbp7dbaHGvtAf/t2UAdY0xcddVnrc3wX+8E3sP5s7YkV/ef3zBgqbV2R+kNbu+/EnYcHIryX+8so43bn8XxwDnA5dY/4FtaAJ+HKmGt3WGt9VprfcAL5byv2/svArgQeLO8Nm7tvyMRzIH+I5BsjGnn78WNAj4s1eZDYJx/tsZAIPvgn8ZVzT/e9hKw1lr7WDltmvvbYYzpj7O/q2VpYWNMtDEm9uBtnC/OVpVq5tr+K6HcXpGb+6+UD4Hx/tvjgQ/KaBPI57VKGGOG4pyD4DxrbV45bQL5PFRVfSW/l7mgnPd1bf/5nQmss9amlbXRzf13RNz+VvZwF5xZGBtwvv3+m/+xicBE/22Dc77TzcBKIKUaazsJ50/CFcAy/2V4qfomAatxvrFfBJxYjfW197/vcn8NQbX//O9fHyegG5Z4zNX9h/OfSyZQjNNrvApnJdEvgI3+6yb+ti2A2Yf7vFZTfZtwxp8Pfg4nl66vvM9DNdX3mv/ztQInpBODaf/5H3/l4OeuRNtq33/HetGh/yIiISKYh1xEROQIKNBFREKEAl1EJEQo0EVEQoQCXUQkRCjQRURChAJdRCRE/D/9VNZlrNe4CAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 28.118159, Train accuracy: 0.232333, val accuracy: 0.237000\n",
      "Loss: 23.601154, Train accuracy: 0.265333, val accuracy: 0.263000\n",
      "Loss: 20.200291, Train accuracy: 0.318444, val accuracy: 0.311000\n",
      "Loss: 16.964565, Train accuracy: 0.349889, val accuracy: 0.358000\n",
      "Loss: 14.553134, Train accuracy: 0.399333, val accuracy: 0.403000\n",
      "Loss: 12.903399, Train accuracy: 0.442556, val accuracy: 0.448000\n",
      "Loss: 10.717856, Train accuracy: 0.463667, val accuracy: 0.467000\n",
      "Loss: 9.471030, Train accuracy: 0.492333, val accuracy: 0.477000\n",
      "Loss: 8.216975, Train accuracy: 0.512333, val accuracy: 0.502000\n",
      "Loss: 7.320452, Train accuracy: 0.535111, val accuracy: 0.526000\n",
      "Loss: 6.323233, Train accuracy: 0.553333, val accuracy: 0.542000\n",
      "Loss: 5.737314, Train accuracy: 0.554111, val accuracy: 0.536000\n",
      "Loss: 4.879599, Train accuracy: 0.565889, val accuracy: 0.547000\n",
      "Loss: 4.484336, Train accuracy: 0.582111, val accuracy: 0.569000\n",
      "Loss: 4.420973, Train accuracy: 0.586667, val accuracy: 0.572000\n",
      "Loss: 3.928654, Train accuracy: 0.590444, val accuracy: 0.576000\n",
      "Loss: 3.602923, Train accuracy: 0.602444, val accuracy: 0.591000\n",
      "Loss: 3.397920, Train accuracy: 0.608889, val accuracy: 0.589000\n",
      "Loss: 3.136438, Train accuracy: 0.610000, val accuracy: 0.594000\n",
      "Loss: 2.884433, Train accuracy: 0.614889, val accuracy: 0.604000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 28.056102, Train accuracy: 0.230000, val accuracy: 0.226000\n",
      "Loss: 23.735678, Train accuracy: 0.269333, val accuracy: 0.264000\n",
      "Loss: 20.105021, Train accuracy: 0.300889, val accuracy: 0.294000\n",
      "Loss: 17.000109, Train accuracy: 0.344778, val accuracy: 0.357000\n",
      "Loss: 14.813773, Train accuracy: 0.397778, val accuracy: 0.392000\n",
      "Loss: 12.652947, Train accuracy: 0.430889, val accuracy: 0.433000\n",
      "Loss: 10.921232, Train accuracy: 0.459556, val accuracy: 0.471000\n",
      "Loss: 9.545149, Train accuracy: 0.480667, val accuracy: 0.481000\n",
      "Loss: 8.228750, Train accuracy: 0.500333, val accuracy: 0.505000\n",
      "Loss: 7.171249, Train accuracy: 0.525889, val accuracy: 0.531000\n",
      "Loss: 6.389941, Train accuracy: 0.549667, val accuracy: 0.548000\n",
      "Loss: 5.966290, Train accuracy: 0.556111, val accuracy: 0.549000\n",
      "Loss: 5.315978, Train accuracy: 0.572000, val accuracy: 0.566000\n",
      "Loss: 4.835098, Train accuracy: 0.571000, val accuracy: 0.579000\n",
      "Loss: 4.128659, Train accuracy: 0.581889, val accuracy: 0.580000\n",
      "Loss: 3.746448, Train accuracy: 0.593778, val accuracy: 0.585000\n",
      "Loss: 3.749290, Train accuracy: 0.605444, val accuracy: 0.589000\n",
      "Loss: 3.700632, Train accuracy: 0.609444, val accuracy: 0.601000\n",
      "Loss: 2.923542, Train accuracy: 0.606556, val accuracy: 0.596000\n",
      "Loss: 3.263041, Train accuracy: 0.612000, val accuracy: 0.597000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-3, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 33.309892, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 32.488487, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Loss: 30.811116, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 30.473542, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 30.018279, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 29.448835, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 28.814563, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 28.407421, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 28.145741, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 27.869177, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 27.407869, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 26.964321, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 26.758952, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 26.291153, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 25.967601, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 25.764320, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 25.390980, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 25.157191, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 24.755063, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 24.502641, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 24.203473, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 23.921210, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 23.672943, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 23.304200, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 23.058571, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 22.807307, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 22.519588, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 22.227265, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 21.954275, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 21.725166, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 21.458234, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 21.185394, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 20.985341, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 20.717825, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 20.482961, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 20.215603, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 19.991527, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 19.744067, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 19.505745, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 19.270803, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 19.053968, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 18.812083, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 18.608483, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 18.386074, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 18.163791, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 17.965814, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 17.757792, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 17.522914, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 17.324253, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 17.125909, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 16.933874, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 16.711965, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 16.511487, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 16.338741, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 16.148077, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.938923, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.766164, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.581790, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.406346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.213609, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 15.023655, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 14.851124, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 14.674828, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 14.521661, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 14.338147, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 14.153773, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.979945, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.828158, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.681642, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.507643, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.348706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.181601, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 13.047875, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 12.880691, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 12.741369, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 12.574013, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 12.447194, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 12.283707, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 12.155517, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.993459, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.867750, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.723324, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.596550, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.452446, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.313530, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.191486, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 11.051347, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.930696, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.795688, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.687826, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.544696, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.422866, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.309153, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.182465, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 10.070284, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.945303, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.840966, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.719834, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.598450, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.495792, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.362445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.281356, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.156613, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 9.061697, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.956727, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.837889, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.732445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.641284, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.546287, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.450556, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.335893, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.232965, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.155695, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 8.052681, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.962293, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.863483, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.767384, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.686928, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.585542, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.510228, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.408708, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.327194, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.257994, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.167315, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.091370, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 7.008906, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.923016, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.845418, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.774502, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.675311, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.603541, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.536328, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.463363, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.388774, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.308247, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.258720, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.160041, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.102342, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 6.023967, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.944387, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.878787, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.826493, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.748819, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.669222, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.620588, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.548896, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.486105, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.438803, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.368718, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 5.294955, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 33.008283, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 31.924683, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 30.546440, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 30.064578, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 29.505054, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 29.511334, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 29.083928, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 28.380044, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 27.996059, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 27.585005, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 27.326736, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 26.913475, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 26.660170, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 26.281010, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 26.056145, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 25.680431, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 25.338877, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 25.064810, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 24.807981, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 24.475802, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.01, reg_strength: 0.001, \n",
      "                    hidden_layer_size: 100, num_epoch:50\n",
      "Loss: 5.141705, Train accuracy: 0.371333, val accuracy: 0.361000\n",
      "Loss: 4.491518, Train accuracy: 0.542667, val accuracy: 0.524000\n",
      "Loss: 4.003587, Train accuracy: 0.617667, val accuracy: 0.602000\n",
      "Loss: 3.664275, Train accuracy: 0.653889, val accuracy: 0.628000\n",
      "Loss: 3.419832, Train accuracy: 0.696333, val accuracy: 0.669000\n",
      "Loss: 3.184877, Train accuracy: 0.712111, val accuracy: 0.690000\n",
      "Loss: 2.997846, Train accuracy: 0.733000, val accuracy: 0.695000\n",
      "Loss: 2.830382, Train accuracy: 0.730000, val accuracy: 0.710000\n",
      "Loss: 2.674536, Train accuracy: 0.748111, val accuracy: 0.694000\n",
      "Loss: 2.538066, Train accuracy: 0.763667, val accuracy: 0.714000\n",
      "Loss: 2.410490, Train accuracy: 0.777667, val accuracy: 0.709000\n",
      "Loss: 2.287710, Train accuracy: 0.788333, val accuracy: 0.727000\n",
      "Loss: 2.184769, Train accuracy: 0.795333, val accuracy: 0.729000\n",
      "Loss: 2.081597, Train accuracy: 0.806667, val accuracy: 0.743000\n",
      "Loss: 1.987339, Train accuracy: 0.794000, val accuracy: 0.729000\n",
      "Loss: 1.911663, Train accuracy: 0.807444, val accuracy: 0.737000\n",
      "Loss: 1.819420, Train accuracy: 0.807556, val accuracy: 0.730000\n",
      "Loss: 1.744353, Train accuracy: 0.814667, val accuracy: 0.748000\n",
      "Loss: 1.675015, Train accuracy: 0.806444, val accuracy: 0.730000\n",
      "Loss: 1.621665, Train accuracy: 0.827889, val accuracy: 0.751000\n",
      "Loss: 1.551140, Train accuracy: 0.823889, val accuracy: 0.751000\n",
      "Loss: 1.508675, Train accuracy: 0.825000, val accuracy: 0.743000\n",
      "Loss: 1.449807, Train accuracy: 0.840444, val accuracy: 0.751000\n",
      "Loss: 1.404696, Train accuracy: 0.835778, val accuracy: 0.739000\n",
      "Loss: 1.358575, Train accuracy: 0.837111, val accuracy: 0.737000\n",
      "Loss: 1.320999, Train accuracy: 0.849778, val accuracy: 0.757000\n",
      "Loss: 1.284034, Train accuracy: 0.846222, val accuracy: 0.739000\n",
      "Loss: 1.242070, Train accuracy: 0.850111, val accuracy: 0.747000\n",
      "Loss: 1.212052, Train accuracy: 0.860111, val accuracy: 0.750000\n",
      "Loss: 1.182119, Train accuracy: 0.868222, val accuracy: 0.763000\n",
      "Loss: 1.148022, Train accuracy: 0.874222, val accuracy: 0.757000\n",
      "Loss: 1.135990, Train accuracy: 0.872444, val accuracy: 0.764000\n",
      "Loss: 1.104616, Train accuracy: 0.872889, val accuracy: 0.764000\n",
      "Loss: 1.085261, Train accuracy: 0.879556, val accuracy: 0.767000\n",
      "Loss: 1.068151, Train accuracy: 0.878778, val accuracy: 0.767000\n",
      "Loss: 1.043844, Train accuracy: 0.872778, val accuracy: 0.766000\n",
      "Loss: 1.033703, Train accuracy: 0.871333, val accuracy: 0.758000\n",
      "Loss: 0.998797, Train accuracy: 0.887333, val accuracy: 0.773000\n",
      "Loss: 0.992527, Train accuracy: 0.872111, val accuracy: 0.759000\n",
      "Loss: 0.982729, Train accuracy: 0.887556, val accuracy: 0.764000\n",
      "Loss: 0.964312, Train accuracy: 0.877333, val accuracy: 0.758000\n",
      "Loss: 0.946359, Train accuracy: 0.884444, val accuracy: 0.762000\n",
      "Loss: 0.935673, Train accuracy: 0.887667, val accuracy: 0.766000\n",
      "Loss: 0.927954, Train accuracy: 0.903778, val accuracy: 0.779000\n",
      "Loss: 0.903126, Train accuracy: 0.890222, val accuracy: 0.772000\n",
      "Loss: 0.897021, Train accuracy: 0.885333, val accuracy: 0.770000\n",
      "Loss: 0.894596, Train accuracy: 0.890778, val accuracy: 0.767000\n",
      "Loss: 0.890586, Train accuracy: 0.899556, val accuracy: 0.776000\n",
      "Loss: 0.888751, Train accuracy: 0.885778, val accuracy: 0.764000\n",
      "Loss: 0.868964, Train accuracy: 0.889889, val accuracy: 0.775000\n",
      "learning_rate: 0.01, reg_strength: 0.001, \n",
      "                    hidden_layer_size: 100, num_epoch:75\n",
      "Loss: 5.138870, Train accuracy: 0.350333, val accuracy: 0.343000\n",
      "Loss: 4.502797, Train accuracy: 0.523667, val accuracy: 0.517000\n",
      "Loss: 4.029642, Train accuracy: 0.614333, val accuracy: 0.590000\n",
      "Loss: 3.697367, Train accuracy: 0.663444, val accuracy: 0.622000\n",
      "Loss: 3.427090, Train accuracy: 0.679889, val accuracy: 0.658000\n",
      "Loss: 3.206153, Train accuracy: 0.717667, val accuracy: 0.672000\n",
      "Loss: 3.015106, Train accuracy: 0.737333, val accuracy: 0.683000\n",
      "Loss: 2.840965, Train accuracy: 0.752778, val accuracy: 0.705000\n",
      "Loss: 2.696398, Train accuracy: 0.756889, val accuracy: 0.717000\n",
      "Loss: 2.548612, Train accuracy: 0.760111, val accuracy: 0.700000\n",
      "Loss: 2.415696, Train accuracy: 0.774111, val accuracy: 0.722000\n",
      "Loss: 2.295431, Train accuracy: 0.774444, val accuracy: 0.722000\n",
      "Loss: 2.195227, Train accuracy: 0.796778, val accuracy: 0.727000\n",
      "Loss: 2.098738, Train accuracy: 0.795444, val accuracy: 0.716000\n",
      "Loss: 2.012460, Train accuracy: 0.794111, val accuracy: 0.719000\n",
      "Loss: 1.914632, Train accuracy: 0.813556, val accuracy: 0.734000\n",
      "Loss: 1.825346, Train accuracy: 0.818556, val accuracy: 0.746000\n",
      "Loss: 1.746905, Train accuracy: 0.805000, val accuracy: 0.735000\n",
      "Loss: 1.684099, Train accuracy: 0.835444, val accuracy: 0.752000\n",
      "Loss: 1.617420, Train accuracy: 0.825889, val accuracy: 0.731000\n",
      "Loss: 1.559240, Train accuracy: 0.834667, val accuracy: 0.753000\n",
      "Loss: 1.506101, Train accuracy: 0.834222, val accuracy: 0.746000\n",
      "Loss: 1.455637, Train accuracy: 0.824333, val accuracy: 0.752000\n",
      "Loss: 1.421653, Train accuracy: 0.847889, val accuracy: 0.747000\n",
      "Loss: 1.368668, Train accuracy: 0.856000, val accuracy: 0.748000\n",
      "Loss: 1.316186, Train accuracy: 0.832556, val accuracy: 0.751000\n",
      "Loss: 1.283814, Train accuracy: 0.859222, val accuracy: 0.750000\n",
      "Loss: 1.248146, Train accuracy: 0.845667, val accuracy: 0.747000\n",
      "Loss: 1.208349, Train accuracy: 0.859333, val accuracy: 0.755000\n",
      "Loss: 1.181422, Train accuracy: 0.867000, val accuracy: 0.767000\n",
      "Loss: 1.157614, Train accuracy: 0.850667, val accuracy: 0.760000\n",
      "Loss: 1.129046, Train accuracy: 0.859556, val accuracy: 0.752000\n",
      "Loss: 1.101327, Train accuracy: 0.878444, val accuracy: 0.755000\n",
      "Loss: 1.088822, Train accuracy: 0.856889, val accuracy: 0.755000\n",
      "Loss: 1.059917, Train accuracy: 0.871333, val accuracy: 0.769000\n",
      "Loss: 1.041813, Train accuracy: 0.883667, val accuracy: 0.763000\n",
      "Loss: 1.025138, Train accuracy: 0.883333, val accuracy: 0.754000\n",
      "Loss: 1.000285, Train accuracy: 0.885889, val accuracy: 0.757000\n",
      "Loss: 0.970551, Train accuracy: 0.891667, val accuracy: 0.765000\n",
      "Loss: 0.962881, Train accuracy: 0.880556, val accuracy: 0.779000\n",
      "Loss: 0.942758, Train accuracy: 0.883222, val accuracy: 0.762000\n",
      "Loss: 0.938470, Train accuracy: 0.864222, val accuracy: 0.753000\n",
      "Loss: 0.922701, Train accuracy: 0.899778, val accuracy: 0.772000\n",
      "Loss: 0.908197, Train accuracy: 0.873778, val accuracy: 0.748000\n",
      "Loss: 0.895604, Train accuracy: 0.900000, val accuracy: 0.764000\n",
      "Loss: 0.886780, Train accuracy: 0.898333, val accuracy: 0.769000\n",
      "Loss: 0.880088, Train accuracy: 0.894556, val accuracy: 0.772000\n",
      "Loss: 0.878471, Train accuracy: 0.899778, val accuracy: 0.764000\n",
      "Loss: 0.867599, Train accuracy: 0.894222, val accuracy: 0.771000\n",
      "Loss: 0.851795, Train accuracy: 0.901111, val accuracy: 0.773000\n",
      "Loss: 0.849589, Train accuracy: 0.912333, val accuracy: 0.774000\n",
      "Loss: 0.846357, Train accuracy: 0.901889, val accuracy: 0.773000\n",
      "Loss: 0.820577, Train accuracy: 0.913111, val accuracy: 0.779000\n",
      "Loss: 0.809335, Train accuracy: 0.903444, val accuracy: 0.765000\n",
      "Loss: 0.806894, Train accuracy: 0.913222, val accuracy: 0.770000\n",
      "Loss: 0.795169, Train accuracy: 0.905778, val accuracy: 0.783000\n",
      "Loss: 0.788453, Train accuracy: 0.893556, val accuracy: 0.759000\n",
      "Loss: 0.778000, Train accuracy: 0.909556, val accuracy: 0.775000\n",
      "Loss: 0.777309, Train accuracy: 0.912667, val accuracy: 0.779000\n",
      "Loss: 0.775197, Train accuracy: 0.914778, val accuracy: 0.777000\n",
      "learning_rate: 0.01, reg_strength: 0.001, \n",
      "                    hidden_layer_size: 150, num_epoch:50\n",
      "Loss: 6.602542, Train accuracy: 0.423111, val accuracy: 0.396000\n",
      "Loss: 5.813014, Train accuracy: 0.549556, val accuracy: 0.541000\n",
      "Loss: 5.252756, Train accuracy: 0.641889, val accuracy: 0.603000\n",
      "Loss: 4.839152, Train accuracy: 0.684667, val accuracy: 0.640000\n",
      "Loss: 4.497641, Train accuracy: 0.703111, val accuracy: 0.658000\n",
      "Loss: 4.212140, Train accuracy: 0.725667, val accuracy: 0.680000\n",
      "Loss: 3.941365, Train accuracy: 0.738222, val accuracy: 0.691000\n",
      "Loss: 3.704821, Train accuracy: 0.744778, val accuracy: 0.697000\n",
      "Loss: 3.495094, Train accuracy: 0.754444, val accuracy: 0.708000\n",
      "Loss: 3.297303, Train accuracy: 0.777222, val accuracy: 0.718000\n",
      "Loss: 3.112230, Train accuracy: 0.788667, val accuracy: 0.718000\n",
      "Loss: 2.949585, Train accuracy: 0.789778, val accuracy: 0.739000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.786356, Train accuracy: 0.792444, val accuracy: 0.708000\n",
      "Loss: 2.643779, Train accuracy: 0.816889, val accuracy: 0.732000\n",
      "Loss: 2.515561, Train accuracy: 0.800000, val accuracy: 0.716000\n",
      "Loss: 2.388344, Train accuracy: 0.832444, val accuracy: 0.742000\n",
      "Loss: 2.272860, Train accuracy: 0.795778, val accuracy: 0.703000\n",
      "Loss: 2.171464, Train accuracy: 0.831444, val accuracy: 0.747000\n",
      "Loss: 2.064413, Train accuracy: 0.842667, val accuracy: 0.732000\n",
      "Loss: 1.972110, Train accuracy: 0.838556, val accuracy: 0.750000\n",
      "Loss: 1.892233, Train accuracy: 0.842333, val accuracy: 0.753000\n",
      "Loss: 1.810522, Train accuracy: 0.841667, val accuracy: 0.739000\n",
      "Loss: 1.745602, Train accuracy: 0.856667, val accuracy: 0.767000\n",
      "Loss: 1.668920, Train accuracy: 0.849222, val accuracy: 0.737000\n",
      "Loss: 1.608092, Train accuracy: 0.867111, val accuracy: 0.748000\n",
      "Loss: 1.551749, Train accuracy: 0.870222, val accuracy: 0.753000\n",
      "Loss: 1.491111, Train accuracy: 0.852667, val accuracy: 0.741000\n",
      "Loss: 1.450624, Train accuracy: 0.878111, val accuracy: 0.751000\n",
      "Loss: 1.391868, Train accuracy: 0.885000, val accuracy: 0.760000\n",
      "Loss: 1.352393, Train accuracy: 0.887556, val accuracy: 0.756000\n",
      "Loss: 1.314155, Train accuracy: 0.881000, val accuracy: 0.756000\n",
      "Loss: 1.274121, Train accuracy: 0.891889, val accuracy: 0.760000\n",
      "Loss: 1.235563, Train accuracy: 0.855333, val accuracy: 0.750000\n",
      "Loss: 1.194541, Train accuracy: 0.854333, val accuracy: 0.728000\n",
      "Loss: 1.183294, Train accuracy: 0.891111, val accuracy: 0.759000\n",
      "Loss: 1.136537, Train accuracy: 0.888000, val accuracy: 0.760000\n",
      "Loss: 1.110455, Train accuracy: 0.890667, val accuracy: 0.761000\n",
      "Loss: 1.091827, Train accuracy: 0.895444, val accuracy: 0.760000\n",
      "Loss: 1.076702, Train accuracy: 0.887889, val accuracy: 0.756000\n",
      "Loss: 1.036632, Train accuracy: 0.901333, val accuracy: 0.762000\n",
      "Loss: 1.010641, Train accuracy: 0.881778, val accuracy: 0.747000\n",
      "Loss: 1.004684, Train accuracy: 0.893111, val accuracy: 0.756000\n",
      "Loss: 0.973627, Train accuracy: 0.915444, val accuracy: 0.772000\n",
      "Loss: 0.953827, Train accuracy: 0.905111, val accuracy: 0.769000\n",
      "Loss: 0.949435, Train accuracy: 0.908889, val accuracy: 0.771000\n",
      "Loss: 0.928025, Train accuracy: 0.914778, val accuracy: 0.763000\n",
      "Loss: 0.918417, Train accuracy: 0.909556, val accuracy: 0.770000\n",
      "Loss: 0.911544, Train accuracy: 0.914556, val accuracy: 0.763000\n",
      "learning_rate: 0.01, reg_strength: 0.001, \n",
      "                    hidden_layer_size: 150, num_epoch:75\n",
      "Loss: 6.613634, Train accuracy: 0.407444, val accuracy: 0.390000\n",
      "Loss: 5.838695, Train accuracy: 0.557556, val accuracy: 0.535000\n",
      "Loss: 5.271967, Train accuracy: 0.605333, val accuracy: 0.587000\n",
      "Loss: 4.859160, Train accuracy: 0.671333, val accuracy: 0.648000\n",
      "Loss: 4.526319, Train accuracy: 0.696333, val accuracy: 0.662000\n",
      "Loss: 4.218701, Train accuracy: 0.720778, val accuracy: 0.679000\n",
      "Loss: 3.957862, Train accuracy: 0.742556, val accuracy: 0.692000\n",
      "Loss: 3.713252, Train accuracy: 0.753444, val accuracy: 0.716000\n",
      "Loss: 3.494656, Train accuracy: 0.766444, val accuracy: 0.718000\n",
      "Loss: 3.295944, Train accuracy: 0.774889, val accuracy: 0.706000\n",
      "Loss: 3.122304, Train accuracy: 0.783111, val accuracy: 0.728000\n",
      "Loss: 2.940464, Train accuracy: 0.801889, val accuracy: 0.722000\n",
      "Loss: 2.785804, Train accuracy: 0.806222, val accuracy: 0.748000\n",
      "Loss: 2.638793, Train accuracy: 0.818111, val accuracy: 0.731000\n",
      "Loss: 2.509654, Train accuracy: 0.824444, val accuracy: 0.738000\n",
      "Loss: 2.397958, Train accuracy: 0.818556, val accuracy: 0.728000\n",
      "Loss: 2.276638, Train accuracy: 0.820444, val accuracy: 0.731000\n",
      "Loss: 2.159709, Train accuracy: 0.839889, val accuracy: 0.732000\n",
      "Loss: 2.068778, Train accuracy: 0.827222, val accuracy: 0.730000\n",
      "Loss: 1.976732, Train accuracy: 0.845333, val accuracy: 0.739000\n",
      "Loss: 1.892283, Train accuracy: 0.843889, val accuracy: 0.737000\n",
      "Loss: 1.815681, Train accuracy: 0.863000, val accuracy: 0.741000\n",
      "Loss: 1.746167, Train accuracy: 0.870333, val accuracy: 0.745000\n",
      "Loss: 1.671266, Train accuracy: 0.853889, val accuracy: 0.762000\n",
      "Loss: 1.599371, Train accuracy: 0.877778, val accuracy: 0.757000\n",
      "Loss: 1.546623, Train accuracy: 0.861111, val accuracy: 0.733000\n",
      "Loss: 1.488052, Train accuracy: 0.876222, val accuracy: 0.756000\n",
      "Loss: 1.431969, Train accuracy: 0.877333, val accuracy: 0.752000\n",
      "Loss: 1.406759, Train accuracy: 0.879667, val accuracy: 0.760000\n",
      "Loss: 1.343024, Train accuracy: 0.861000, val accuracy: 0.753000\n",
      "Loss: 1.305657, Train accuracy: 0.884333, val accuracy: 0.753000\n",
      "Loss: 1.269985, Train accuracy: 0.870444, val accuracy: 0.747000\n",
      "Loss: 1.231023, Train accuracy: 0.881444, val accuracy: 0.757000\n",
      "Loss: 1.200226, Train accuracy: 0.896111, val accuracy: 0.770000\n",
      "Loss: 1.165993, Train accuracy: 0.896556, val accuracy: 0.766000\n",
      "Loss: 1.142046, Train accuracy: 0.878222, val accuracy: 0.754000\n",
      "Loss: 1.112030, Train accuracy: 0.884444, val accuracy: 0.768000\n",
      "Loss: 1.100307, Train accuracy: 0.897444, val accuracy: 0.757000\n",
      "Loss: 1.060559, Train accuracy: 0.892222, val accuracy: 0.767000\n",
      "Loss: 1.054079, Train accuracy: 0.879000, val accuracy: 0.755000\n",
      "Loss: 1.019736, Train accuracy: 0.903889, val accuracy: 0.763000\n",
      "Loss: 1.015682, Train accuracy: 0.904667, val accuracy: 0.776000\n",
      "Loss: 0.992476, Train accuracy: 0.905778, val accuracy: 0.772000\n",
      "Loss: 0.976015, Train accuracy: 0.898333, val accuracy: 0.758000\n",
      "Loss: 0.950122, Train accuracy: 0.904778, val accuracy: 0.752000\n",
      "Loss: 0.941287, Train accuracy: 0.888778, val accuracy: 0.751000\n",
      "Loss: 0.940147, Train accuracy: 0.904333, val accuracy: 0.777000\n",
      "Loss: 0.914666, Train accuracy: 0.902778, val accuracy: 0.771000\n",
      "Loss: 0.901339, Train accuracy: 0.909222, val accuracy: 0.768000\n",
      "Loss: 0.883023, Train accuracy: 0.908000, val accuracy: 0.763000\n",
      "Loss: 0.875822, Train accuracy: 0.915333, val accuracy: 0.772000\n",
      "Loss: 0.871042, Train accuracy: 0.911333, val accuracy: 0.757000\n",
      "Loss: 0.864887, Train accuracy: 0.897444, val accuracy: 0.765000\n",
      "Loss: 0.851800, Train accuracy: 0.912000, val accuracy: 0.768000\n",
      "Loss: 0.845384, Train accuracy: 0.921667, val accuracy: 0.762000\n",
      "Loss: 0.835135, Train accuracy: 0.916111, val accuracy: 0.767000\n",
      "Loss: 0.826322, Train accuracy: 0.918111, val accuracy: 0.762000\n",
      "Loss: 0.813472, Train accuracy: 0.927778, val accuracy: 0.783000\n",
      "Loss: 0.806489, Train accuracy: 0.929667, val accuracy: 0.767000\n",
      "Loss: 0.802996, Train accuracy: 0.923111, val accuracy: 0.772000\n",
      "Loss: 0.796254, Train accuracy: 0.916556, val accuracy: 0.765000\n",
      "Loss: 0.795742, Train accuracy: 0.919444, val accuracy: 0.774000\n",
      "Loss: 0.789731, Train accuracy: 0.908222, val accuracy: 0.758000\n",
      "Loss: 0.783549, Train accuracy: 0.920111, val accuracy: 0.760000\n",
      "Loss: 0.777232, Train accuracy: 0.933222, val accuracy: 0.780000\n",
      "Loss: 0.766457, Train accuracy: 0.901333, val accuracy: 0.754000\n",
      "Loss: 0.763182, Train accuracy: 0.919333, val accuracy: 0.775000\n",
      "learning_rate: 0.01, reg_strength: 0.001, \n",
      "                    hidden_layer_size: 200, num_epoch:50\n",
      "Loss: 8.079798, Train accuracy: 0.431444, val accuracy: 0.420000\n",
      "Loss: 7.158261, Train accuracy: 0.570667, val accuracy: 0.536000\n",
      "Loss: 6.499160, Train accuracy: 0.647778, val accuracy: 0.613000\n",
      "Loss: 5.998894, Train accuracy: 0.702778, val accuracy: 0.661000\n",
      "Loss: 5.577355, Train accuracy: 0.718000, val accuracy: 0.661000\n",
      "Loss: 5.208804, Train accuracy: 0.735111, val accuracy: 0.696000\n",
      "Loss: 4.876271, Train accuracy: 0.760667, val accuracy: 0.715000\n",
      "Loss: 4.571775, Train accuracy: 0.768667, val accuracy: 0.703000\n",
      "Loss: 4.297273, Train accuracy: 0.772556, val accuracy: 0.697000\n",
      "Loss: 4.041206, Train accuracy: 0.792333, val accuracy: 0.719000\n",
      "Loss: 3.808469, Train accuracy: 0.800222, val accuracy: 0.718000\n",
      "Loss: 3.592008, Train accuracy: 0.798444, val accuracy: 0.719000\n",
      "Loss: 3.397163, Train accuracy: 0.804000, val accuracy: 0.719000\n",
      "Loss: 3.204039, Train accuracy: 0.823000, val accuracy: 0.747000\n",
      "Loss: 3.035612, Train accuracy: 0.822444, val accuracy: 0.733000\n",
      "Loss: 2.879233, Train accuracy: 0.830667, val accuracy: 0.736000\n",
      "Loss: 2.726028, Train accuracy: 0.837000, val accuracy: 0.731000\n",
      "Loss: 2.578957, Train accuracy: 0.827333, val accuracy: 0.734000\n",
      "Loss: 2.459640, Train accuracy: 0.836667, val accuracy: 0.721000\n",
      "Loss: 2.327643, Train accuracy: 0.859667, val accuracy: 0.752000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.218755, Train accuracy: 0.860889, val accuracy: 0.746000\n",
      "Loss: 2.118893, Train accuracy: 0.862111, val accuracy: 0.749000\n",
      "Loss: 2.024965, Train accuracy: 0.865444, val accuracy: 0.747000\n",
      "Loss: 1.941604, Train accuracy: 0.867556, val accuracy: 0.755000\n",
      "Loss: 1.856789, Train accuracy: 0.870556, val accuracy: 0.757000\n",
      "Loss: 1.773169, Train accuracy: 0.883000, val accuracy: 0.762000\n",
      "Loss: 1.701354, Train accuracy: 0.881333, val accuracy: 0.759000\n",
      "Loss: 1.639217, Train accuracy: 0.885444, val accuracy: 0.770000\n",
      "Loss: 1.577721, Train accuracy: 0.884000, val accuracy: 0.773000\n",
      "Loss: 1.521896, Train accuracy: 0.893444, val accuracy: 0.773000\n",
      "Loss: 1.470204, Train accuracy: 0.890333, val accuracy: 0.768000\n",
      "Loss: 1.414033, Train accuracy: 0.896444, val accuracy: 0.766000\n",
      "Loss: 1.371054, Train accuracy: 0.894000, val accuracy: 0.763000\n",
      "Loss: 1.329232, Train accuracy: 0.904333, val accuracy: 0.766000\n",
      "Loss: 1.284585, Train accuracy: 0.895333, val accuracy: 0.765000\n",
      "Loss: 1.269962, Train accuracy: 0.879556, val accuracy: 0.739000\n",
      "Loss: 1.230479, Train accuracy: 0.901556, val accuracy: 0.769000\n",
      "Loss: 1.184664, Train accuracy: 0.896778, val accuracy: 0.757000\n",
      "Loss: 1.153608, Train accuracy: 0.898889, val accuracy: 0.776000\n",
      "Loss: 1.127199, Train accuracy: 0.895333, val accuracy: 0.773000\n",
      "Loss: 1.106929, Train accuracy: 0.907556, val accuracy: 0.780000\n",
      "Loss: 1.070474, Train accuracy: 0.916000, val accuracy: 0.790000\n",
      "Loss: 1.052320, Train accuracy: 0.914444, val accuracy: 0.767000\n",
      "Loss: 1.025007, Train accuracy: 0.892000, val accuracy: 0.746000\n",
      "Loss: 1.023909, Train accuracy: 0.846667, val accuracy: 0.736000\n",
      "Loss: 1.001023, Train accuracy: 0.903667, val accuracy: 0.757000\n",
      "Loss: 0.977563, Train accuracy: 0.921778, val accuracy: 0.766000\n",
      "Loss: 0.955959, Train accuracy: 0.915333, val accuracy: 0.778000\n",
      "Loss: 0.943468, Train accuracy: 0.910556, val accuracy: 0.771000\n",
      "Loss: 0.938719, Train accuracy: 0.919778, val accuracy: 0.760000\n",
      "learning_rate: 0.01, reg_strength: 0.001, \n",
      "                    hidden_layer_size: 200, num_epoch:75\n",
      "Loss: 8.065109, Train accuracy: 0.416889, val accuracy: 0.380000\n",
      "Loss: 7.153910, Train accuracy: 0.588000, val accuracy: 0.548000\n",
      "Loss: 6.502624, Train accuracy: 0.647667, val accuracy: 0.594000\n",
      "Loss: 6.003071, Train accuracy: 0.684556, val accuracy: 0.625000\n",
      "Loss: 5.575648, Train accuracy: 0.709333, val accuracy: 0.657000\n",
      "Loss: 5.199416, Train accuracy: 0.734111, val accuracy: 0.672000\n",
      "Loss: 4.866528, Train accuracy: 0.760667, val accuracy: 0.684000\n",
      "Loss: 4.558607, Train accuracy: 0.779778, val accuracy: 0.708000\n",
      "Loss: 4.284045, Train accuracy: 0.774889, val accuracy: 0.701000\n",
      "Loss: 4.029926, Train accuracy: 0.797667, val accuracy: 0.711000\n",
      "Loss: 3.797305, Train accuracy: 0.801889, val accuracy: 0.698000\n",
      "Loss: 3.570600, Train accuracy: 0.809222, val accuracy: 0.716000\n",
      "Loss: 3.386564, Train accuracy: 0.814333, val accuracy: 0.718000\n",
      "Loss: 3.188316, Train accuracy: 0.836889, val accuracy: 0.750000\n",
      "Loss: 3.019498, Train accuracy: 0.834333, val accuracy: 0.734000\n",
      "Loss: 2.855522, Train accuracy: 0.826667, val accuracy: 0.724000\n",
      "Loss: 2.706546, Train accuracy: 0.840889, val accuracy: 0.741000\n",
      "Loss: 2.562171, Train accuracy: 0.853222, val accuracy: 0.762000\n",
      "Loss: 2.441174, Train accuracy: 0.859333, val accuracy: 0.753000\n",
      "Loss: 2.316624, Train accuracy: 0.862333, val accuracy: 0.753000\n",
      "Loss: 2.214208, Train accuracy: 0.861889, val accuracy: 0.753000\n",
      "Loss: 2.104989, Train accuracy: 0.869111, val accuracy: 0.757000\n",
      "Loss: 2.016727, Train accuracy: 0.872333, val accuracy: 0.754000\n",
      "Loss: 1.935683, Train accuracy: 0.881667, val accuracy: 0.771000\n",
      "Loss: 1.842586, Train accuracy: 0.872444, val accuracy: 0.766000\n",
      "Loss: 1.775810, Train accuracy: 0.887111, val accuracy: 0.760000\n",
      "Loss: 1.686541, Train accuracy: 0.864778, val accuracy: 0.745000\n",
      "Loss: 1.634464, Train accuracy: 0.889000, val accuracy: 0.763000\n",
      "Loss: 1.567161, Train accuracy: 0.869667, val accuracy: 0.739000\n",
      "Loss: 1.536629, Train accuracy: 0.886667, val accuracy: 0.758000\n",
      "Loss: 1.464643, Train accuracy: 0.904111, val accuracy: 0.766000\n",
      "Loss: 1.404510, Train accuracy: 0.895444, val accuracy: 0.764000\n",
      "Loss: 1.367803, Train accuracy: 0.865444, val accuracy: 0.726000\n",
      "Loss: 1.325199, Train accuracy: 0.891444, val accuracy: 0.767000\n",
      "Loss: 1.277931, Train accuracy: 0.903667, val accuracy: 0.772000\n",
      "Loss: 1.249704, Train accuracy: 0.906000, val accuracy: 0.761000\n",
      "Loss: 1.208334, Train accuracy: 0.910000, val accuracy: 0.772000\n",
      "Loss: 1.176491, Train accuracy: 0.909111, val accuracy: 0.765000\n",
      "Loss: 1.145484, Train accuracy: 0.908889, val accuracy: 0.775000\n",
      "Loss: 1.115626, Train accuracy: 0.915333, val accuracy: 0.785000\n",
      "Loss: 1.088333, Train accuracy: 0.908222, val accuracy: 0.773000\n",
      "Loss: 1.080246, Train accuracy: 0.910778, val accuracy: 0.765000\n",
      "Loss: 1.038752, Train accuracy: 0.916000, val accuracy: 0.767000\n",
      "Loss: 1.028574, Train accuracy: 0.914222, val accuracy: 0.767000\n",
      "Loss: 1.004100, Train accuracy: 0.897444, val accuracy: 0.759000\n",
      "Loss: 0.989283, Train accuracy: 0.906222, val accuracy: 0.762000\n",
      "Loss: 0.967514, Train accuracy: 0.918667, val accuracy: 0.775000\n",
      "Loss: 0.951462, Train accuracy: 0.909222, val accuracy: 0.768000\n",
      "Loss: 0.934477, Train accuracy: 0.906333, val accuracy: 0.764000\n",
      "Loss: 0.920926, Train accuracy: 0.906000, val accuracy: 0.776000\n",
      "Loss: 0.897266, Train accuracy: 0.912111, val accuracy: 0.769000\n",
      "Loss: 0.890842, Train accuracy: 0.919222, val accuracy: 0.765000\n",
      "Loss: 0.877074, Train accuracy: 0.917444, val accuracy: 0.780000\n",
      "Loss: 0.866000, Train accuracy: 0.929111, val accuracy: 0.778000\n",
      "Loss: 0.860146, Train accuracy: 0.918444, val accuracy: 0.772000\n",
      "Loss: 0.854350, Train accuracy: 0.929889, val accuracy: 0.771000\n",
      "Loss: 0.843174, Train accuracy: 0.927111, val accuracy: 0.775000\n",
      "Loss: 0.829509, Train accuracy: 0.928889, val accuracy: 0.777000\n",
      "Loss: 0.827293, Train accuracy: 0.931444, val accuracy: 0.778000\n",
      "Loss: 0.814447, Train accuracy: 0.925889, val accuracy: 0.770000\n",
      "Loss: 0.802122, Train accuracy: 0.927333, val accuracy: 0.769000\n",
      "Loss: 0.788381, Train accuracy: 0.930000, val accuracy: 0.778000\n",
      "Loss: 0.782128, Train accuracy: 0.934667, val accuracy: 0.789000\n",
      "Loss: 0.778743, Train accuracy: 0.934000, val accuracy: 0.777000\n",
      "Loss: 0.773471, Train accuracy: 0.913333, val accuracy: 0.760000\n",
      "Loss: 0.761719, Train accuracy: 0.921111, val accuracy: 0.762000\n",
      "Loss: 0.759371, Train accuracy: 0.936444, val accuracy: 0.772000\n",
      "best validation accuracy achieved: 0.772000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "# learning_rates = 1e-4\n",
    "# reg_strength = 1e-3\n",
    "# learning_rate_decay = 0.999\n",
    "# hidden_layer_size = 128\n",
    "# num_epochs = 200\n",
    "# batch_size = 64\n",
    "\n",
    "learning_rates = [1e-2]\n",
    "reg_strengths = [1e-3]\n",
    "hidden_layer_sizes = [100, 150, 200]\n",
    "num_epoches = [50,75]\n",
    "\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "best_loss_history = []\n",
    "best_train_history = []\n",
    "best_val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "loss = 1e+10\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for reg_strength in reg_strengths:\n",
    "        for hidden_layer_size in hidden_layer_sizes:\n",
    "            for num_epoch in num_epoches:\n",
    "                print(f'''learning_rate: {learning_rate}, reg_strength: {reg_strength}, \n",
    "                    hidden_layer_size: {hidden_layer_size}, num_epoch:{num_epoch}''')\n",
    "                model = TwoLayerNet(train_X.shape[1], 10, hidden_layer_size, reg_strength)\n",
    "                dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "                trainer = Trainer(model, dataset, MomentumSGD(), num_epoch, 50, learning_rate)\n",
    "                loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "                if loss > loss_history[-1]:\n",
    "                    best_classifier = model\n",
    "                    best_loss_history, best_train_history, best_val_history = loss_history, train_history, val_history  \n",
    "                    loss = loss_history[-1]\n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f844aa50e20>]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_classifier = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.758000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
